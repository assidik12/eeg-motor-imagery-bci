{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b40aa4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.datasets import eegbci\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense, LSTM, Reshape, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# =============================================================================\n",
    "# 1. MEMUAT DATA & MEMBUAT GRUP SUBJEK\n",
    "# =============================================================================\n",
    "print(\"Memuat data dari semua subjek...\")\n",
    "\n",
    "subjects = range(1, 21)\n",
    "all_X = []\n",
    "all_y = []\n",
    "groups = []\n",
    "\n",
    "for subject_id in subjects:\n",
    "    print(f\"  Memproses subjek {subject_id}...\")\n",
    "    runs = [6, 10, 14]\n",
    "    raw_files = eegbci.load_data(subject_id, runs, update_path=True, verbose=False)\n",
    "    raw = mne.io.concatenate_raws([mne.io.read_raw_edf(f, preload=True, verbose='WARNING') for f in raw_files])\n",
    "\n",
    "    raw.pick_types(meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "    raw.filter(l_freq=4.0, h_freq=38.0, fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    event_id = dict(T1=1, T2=2)\n",
    "    events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "\n",
    "    tmin, tmax = -1., 4.\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                        proj=True, baseline=None, preload=True, verbose=False)\n",
    "\n",
    "    X_subject = epochs.get_data()\n",
    "    y_subject = epochs.events[:, -1] - 1\n",
    "\n",
    "    all_X.append(X_subject)\n",
    "    all_y.append(y_subject)\n",
    "    groups.append(np.full(len(X_subject), subject_id))\n",
    "\n",
    "X = np.concatenate(all_X, axis=0)\n",
    "y = np.concatenate(all_y, axis=0)\n",
    "groups = np.concatenate(groups, axis=0)\n",
    "\n",
    "print(f\"\\n✅ Data berhasil digabungkan. Bentuk X: {X.shape}, Bentuk y: {y.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. FUNGSI UNTUK MEMBUAT MODEL\n",
    "# =============================================================================\n",
    "def build_model(n_channels, n_timesteps, n_classes):\n",
    "    inputs = Input(shape=(n_channels, n_timesteps, 1))\n",
    "    x = Conv2D(16, (1, 16), activation='elu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (n_channels, 1), activation='elu', padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    target_shape = (n_timesteps, 32)\n",
    "    x = Reshape(target_shape)(x)\n",
    "    x = LSTM(128, return_sequences=False)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(n_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    custom_optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# 3. TAHAP EVALUASI: LOOP VALIDASI SILANG LEAVE-ONE-SUBJECT-OUT (LOSO-CV)\n",
    "# =============================================================================\n",
    "logo = LeaveOneGroupOut()\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):\n",
    "    print(f\"\\n===== FOLD EVALUASI {fold+1}/{len(subjects)} =====\")\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    test_subject = groups[test_idx][0]\n",
    "    print(f\"Training on {len(np.unique(groups[train_idx]))} subjects, Testing on subject {test_subject}\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_reshaped = X_train.reshape(len(X_train), -1)\n",
    "    X_test_reshaped = X_test.reshape(len(X_test), -1)\n",
    "    scaler.fit(X_train_reshaped)\n",
    "    X_train_norm = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "    X_test_norm = scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "    X_train_final = np.expand_dims(X_train_norm, axis=-1)\n",
    "    X_test_final = np.expand_dims(X_test_norm, axis=-1)\n",
    "    y_train_final = to_categorical(y_train)\n",
    "    y_test_final = to_categorical(y_test)\n",
    "\n",
    "    n_channels = X_train_final.shape[1]\n",
    "    n_timesteps = X_train_final.shape[2]\n",
    "    n_classes = y_train_final.shape[1]\n",
    "\n",
    "    model = build_model(n_channels, n_timesteps, n_classes)\n",
    "\n",
    "    # KOREKSI: Cukup gunakan EarlyStopping. ModelCheckpoint tidak diperlukan di sini.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_final, y_train_final,\n",
    "        batch_size=16,\n",
    "        epochs=100,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(X_test_final, y_test_final),\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test_final, y_test_final, verbose=0)\n",
    "    scores.append(accuracy)\n",
    "    print(f\"Accuracy on subject {test_subject}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. HASIL EVALUASI AKHIR\n",
    "# =============================================================================\n",
    "mean_accuracy = np.mean(scores)\n",
    "std_accuracy = np.std(scores)\n",
    "\n",
    "print(\"\\n===== HASIL AKHIR VALIDASI SILANG =====\")\n",
    "print(f\"Akurasi Rata-rata: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standar Deviasi Akurasi: {std_accuracy * 100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(scores)\n",
    "plt.title('Distribusi Akurasi per Subjek (LOSO-CV)')\n",
    "plt.ylabel('Akurasi')\n",
    "plt.xlabel('Model CNN-LSTM')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 5. TAHAP PELATIHAN FINAL\n",
    "# KOREKSI: Latih satu model terakhir menggunakan SEMUA data.\n",
    "# =============================================================================\n",
    "print(\"\\n===== MEMULAI PELATIHAN MODEL FINAL MENGGUNAKAN SEMUA DATA =====\")\n",
    "\n",
    "# 1. Normalisasi menggunakan semua data\n",
    "scaler_final = StandardScaler()\n",
    "X_reshaped_final = X.reshape(len(X), -1)\n",
    "X_norm_final = scaler_final.fit_transform(X_reshaped_final).reshape(X.shape)\n",
    "\n",
    "# 2. Siapkan data untuk model\n",
    "X_final_for_training = np.expand_dims(X_norm_final, axis=-1)\n",
    "y_final_for_training = to_categorical(y)\n",
    "\n",
    "# 3. Bangun dan Latih model final\n",
    "n_channels = X_final_for_training.shape[1]\n",
    "n_timesteps = X_final_for_training.shape[2]\n",
    "n_classes = y_final_for_training.shape[1]\n",
    "\n",
    "final_model = build_model(n_channels, n_timesteps, n_classes)\n",
    "\n",
    "# Latih untuk beberapa epoch saja, karena tidak ada set validasi untuk early stopping\n",
    "# Tujuannya adalah mengekspos model ke semua data yang ada.\n",
    "final_model.fit(\n",
    "    X_final_for_training, y_final_for_training,\n",
    "    batch_size=16,\n",
    "    epochs=15, # Latih untuk jumlah epoch yang wajar\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. Simpan model final untuk portofolio Anda\n",
    "final_model.save('bci_cnn_lstm_final.keras')\n",
    "print(\"\\n✅ Model final berhasil dilatih dan disimpan sebagai 'bci_cnn_lstm_final.keras'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
